{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page  0 , count:  15\n",
      "page  1 , count:  20\n",
      "page  2 , count:  20\n",
      "page  3 , count:  20\n",
      "page  4 , count:  20\n",
      "page  5 , count:  10\n",
      "page  6 , count:  20\n",
      "page  7 , count:  20\n",
      "page  8 , count:  20\n",
      "page  9 , count:  20\n",
      "page  10 , count:  20\n",
      "page  11 , count:  20\n",
      "page  12 , count:  20\n",
      "page  13 , count:  20\n",
      "page  14 , count:  20\n",
      "page  15 , count:  20\n",
      "page  16 , count:  20\n",
      "page  17 , count:  20\n",
      "page  18 , count:  20\n",
      "page  19 , count:  20\n",
      "page  20 , count:  20\n",
      "page  21 , count:  20\n",
      "page  22 , count:  20\n",
      "page  23 , count:  20\n",
      "page  24 , count:  20\n",
      "page  25 , count:  20\n",
      "page  26 , count:  20\n",
      "page  27 , count:  20\n",
      "page  28 , count:  20\n",
      "page  29 , count:  20\n",
      "page  30 , count:  20\n",
      "page  31 , count:  20\n",
      "page  32 , count:  20\n",
      "page  33 , count:  7\n",
      "page  34 , count:  0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "\n",
    "def wait ():    \n",
    "    time.sleep(0.5+(random.randrange(0, 10)*0.05))\n",
    "    \n",
    "url = \"https://nn.hh.ru/search/vacancy\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Language\": \"ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "    \"Connection\": \"keep-alive\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"clusters\": False,\n",
    "    \"ored_clusters\": False,\n",
    "    \"enable_snippets\": False,\n",
    "    \"salary\": None,\n",
    "    \"st\": \"searchVacancy\",\n",
    "    \"text\": \"golang\",\n",
    "    \"page\": 0\n",
    "}\n",
    "\n",
    "vacancys_data = []\n",
    "vacancys_on_page = True \n",
    "\n",
    "while vacancys_on_page:\n",
    "    \n",
    "    response = requests.get(url, headers = headers, params = params)\n",
    "    response_parsed = soup(response.text, 'html.parser')\n",
    "    \n",
    "    # ищем блоки с вакансиями и выдергиваем url\n",
    "    vacancys_on_page = response_parsed.select(\"div[class=vacancy-serp-item]\")  \n",
    "    vacancys_on_page = (vacancys_on_page if len(vacancys_on_page or [])>0 else False)\n",
    "    \n",
    "    # если нашли вакансии - составляем под них структуры с данными\n",
    "    if vacancys_on_page:\n",
    "        for vacancy_block in vacancys_on_page:\n",
    "            link_container = vacancy_block.select(\"a[class='bloko-link']\")\n",
    "            vacancys_data.append({\"url\": link_container[0]['href']})\n",
    "    \n",
    "    print(\"page \", params['page'], \", count: \", len(vacancys_on_page or []) )    \n",
    "    params['page'] += 1\n",
    "    \n",
    "    # симулируем\n",
    "    wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  of  652  :  от 200 000 до 350 000 руб. на руки\n",
      "1  of  652  :  от 25 000 до 105 000 USD до вычета налогов\n",
      "1  of  652  :  от 300 000 руб. на руки\n",
      "1  of  652  :  от 2 500 до 3 500 USD на руки\n",
      "1  of  652  :  от 130 000 до 180 000 руб. на руки\n",
      "1  of  652  :  от 300 000 до 350 000 руб. на руки\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b6c70236e670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# симулируем\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cee87942c0c8>\u001b[0m in \u001b[0;36mwait\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://nn.hh.ru/search/vacancy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# разбираем страницу вакансии\n",
    "counter = 1\n",
    "for data in vacancys_data:\n",
    "    \n",
    "    response = requests.get(data['url'], headers = headers)\n",
    "    response_parsed = soup(response.text, 'html.parser')    \n",
    "   \n",
    "    # вытаскиваем заголовок\n",
    "    \n",
    "    title = response_parsed.select(\"h1[data-qa = 'vacancy-title']\")\n",
    "    title = title[0] or False     \n",
    "    \n",
    "    if title:\n",
    "        for span in title.select(\"span\"):\n",
    "            if \"title\" in data: \n",
    "                data[\"title\"] = str(data[\"title\"])+\" \"+str(span.get_text())\n",
    "            else:\n",
    "                data[\"title\"] = str(span.get_text()) \n",
    "                        \n",
    "    # зарплата бля (\n",
    "    \n",
    "    salary_span = response_parsed.select(\"span[data-qa = 'bloko-header-2'][class = 'bloko-header-2 bloko-header-2_lite']\")\n",
    "    salary_span = salary_span[0] or False\n",
    "    \n",
    "    print(counter,\" of \",len(vacancys_data),\" : \", salary_span.get_text())\n",
    "    counter += 1\n",
    "    \n",
    "    data[\"salary\"] = str(salary_span.get_text())    \n",
    "        \n",
    "    # симулируем\n",
    "    wait()    \n",
    "\n",
    "        \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
